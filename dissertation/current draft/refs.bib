#Note:
    #Quality of citations must be checked: Some must be articles & published papers instead

@article{lip_reading_used_by_everyone,
author = {Woodhouse, Lynn and Hickson, Louise and Dodd, Barbara},
title = {Review of visual speech perception by hearing and hearing-impaired people: clinical implications},
journal = {International Journal of Language \& Communication Disorders},
volume = {44},
number = {3},
pages = {253-270},
keywords = {speech perception, hearing impairment, speech-reading, assessment},
doi = {https://doi.org/10.1080/13682820802090281},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1080/13682820802090281},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1080/13682820802090281},
abstract = {Background: Speech perception is often considered specific to the auditory modality, despite convincing evidence that speech processing is bimodal. The theoretical and clinical roles of speech-reading for speech perception, however, have received little attention in speech–language therapy. Aims: The role of speech-read information for speech perception is evaluated by considering evidence from hearing infants and adults, people with speech disorders, and those born profoundly hearing impaired. Methods \& Procedures: Research studies are evaluated for evidence on lip-reading for speech perception: the mandatory role of speech-reading for hearing adults' perception of the McGurk effect and hearing infants' awareness of the congruence between lip movements and speech sounds; brain neuroimaging studies of speech-read and heard speech perception; the speech-reading abilities of people with disordered speech; and the phonological coding abilities of people with profound pre-lingual hearing loss. Theories of multimodal speech perception are explained. Main Contributions: Five pieces of evidence indicate that speech-reading is an integral part of speech processing. Hearing people's perception of speech is influenced by speech-read cues, and those speech-read cues cannot be ignored. Infants are aware that lip movements and speech sounds match from soon after birth and by four months of age have language specific speech-reading skills. Studies of brain activity show that the brain processes speech-read and heard speech similarly. Some children and adults with speech disorders are reported to rely less on speech-read cues than people without speech disorders, and children who are profoundly hearing impaired from birth have concepts of rhyme, match homophones, and can repeat and spell nonsense words. Conclusions \& Implications: Speech-reading, a mandatory part of speech perception, should be appropriately assessed and be considered when developing strategies for speech and language intervention.},
year = {2009}
}

@misc{WHO_rising_hearing_loss,
author = {{World Health Organization}},
title = {Addressing the rising prevalence of hearing losss},
url = {https://www.who.int/news-room/fact-sheets/detail/deafness-and-hearing-loss},
year = {2018}
}

@misc{WHO_deafness_stats,
author = {{World Health Organization}},
title = {Deafness and hearing loss},
url = {https://www.who.int/publications/i/item/addressing-the-rising-prevalence-of-hearing-loss},
year = {2023}
}

@article{deafness_4th_disability,
author = {Cunningham, Lisa L. and Tucci, Debara L.},
title = {Hearing Loss in Adults},
journal = {New England Journal of Medicine},
volume = {377},
number = {25},
pages = {2465-2473},
year = {2017},
doi = {10.1056/NEJMra1616601},
    note ={PMID: 29262274},

URL = { 
    
        https://doi.org/10.1056/NEJMra1616601
    
    

},
eprint = { 
    
        https://doi.org/10.1056/NEJMra1616601
    
    

}

}

@article{audio-visual_processing_better,
  title={The processing of audio-visual speech: empirical and neural bases},
  author={Campbell, Ruth},
  journal={Philosophical Transactions of the Royal Society B: Biological Sciences},
  volume={363},
  number={1493},
  pages={1001--1010},
  year={2008},
  publisher={The Royal Society London}
}

@inproceedings{Lip-Reading-In-The-Wild,
  title={Lip reading in the wild},
  author={Chung, Joon Son and Zisserman, Andrew},
  booktitle={Computer Vision--ACCV 2016: 13th Asian Conference on Computer Vision, Taipei, Taiwan, November 20-24, 2016, Revised Selected Papers, Part II 13},
  pages={87--103},
  year={2017},
  organization={Springer}
}

@misc{44_phonemes,
author = {Geylanioglu, Savas},
year = {2017},
month = {06},
pages = {},
title = {DEVELOPING {English} LANGUAGE LEARNERS’ PRONUNCIATION THROUGH CONCEPTUALIZATION}
}
@inproceedings{phoneme_viseme_mapping_review,
  title={Which phoneme-to-viseme maps best improve visual-only computer lip-reading?},
  author={Bear, Helen L and Harvey, Richard W and Theobald, Barry-John and Lan, Yuxuan},
  booktitle={Advances in Visual Computing: 10th International Symposium, ISVC 2014, Las Vegas, NV, USA, December 8-10, 2014, Proceedings, Part II 10},
  pages={230--239},
  year={2014},
  organization={Springer}
}
@inproceedings{best_phoneme_viseme_mapping,
  title={Audio-to-visual conversion using hidden markov models},
  author={Lee, Soonkyu and Yook, DongSuk},
  booktitle={Pacific Rim International Conference on Artificial Intelligence},
  pages={563--570},
  year={2002},
  organization={Springer}
}
@misc{7000_languages_globally,
  title={The processing of audio-visual speech: empirical and neural bases},
  author={Garvit Vyas},
  year={2023},
  publisher={Market Research Future},
  url={https://www.marketresearchfuture.com/news/most-spoken-languages-over-the-world-in-2023#:~:text=With%20different%20sounds%20and%20history,it%20as%20the%20second%20language.}
}
@misc{Keras-vs-TF-vs-PT,
  title={Keras vs Tensorflow vs Pytorch: Key Differences Among Deep Learning},
  author={John Terra},
  year={2023},
  publisher={Simplilearn},
  url={https://www.simplilearn.com/keras-vs-tensorflow-vs-pytorch-article#:~:text=5)%20Should%20I%20learn%20PyTorch,PyTorch%20is%20the%20suitable%20option.}
}
@misc{cross_entropy_loss,
  title={Cross Entropy Loss: Intro, Applications, Code},
  author={Deval Shah},
  year={2023},
  publisher={V7 Labs},
  url={https://www.v7labs.com/blog/cross-entropy-loss-guide}
}
@inproceedings{Cross-Linguistic-Phoneme-Correspondences,
  title={Cross Linguistic Phoneme Correspondences},
  author={Cahill, Lynne and Tiberius, Carole},
  booktitle={COLING 2002: The 17th International Conference on Computational Linguistics: Project Notes},
  year={2002}
}
@article{lip_reading_multimodal,
  title={Interaction of audition and vision in the recognition of oral speech stimuli},
  author={Erber, Norman P},
  journal={Journal of speech and hearing research},
  volume={12},
  number={2},
  pages={423--425},
  year={1969},
  publisher={ASHA}
}
@article{Effects-of-context-type-on-lipreading,
  title={Effects of context type on lipreading and listening performance and implications for sentence processing},
  author={Spehar, Brent and Goebel, Stacey and Tye-Murray, Nancy},
  journal={Journal of speech, language, and hearing research},
  volume={58},
  number={3},
  pages={1093--1102},
  year={2015},
  publisher={ASHA}
}
@inproceedings{mediapipe_info,
  title={Mediapipe: A framework for perceiving and processing reality},
  author={Lugaresi, Camillo and Tang, Jiuqiang and Nash, Hadon and McClanahan, Chris and Uboweja, Esha and Hays, Michael and Zhang, Fan and Chang, Chuo-Ling and Yong, Ming and Lee, Juhyun and others},
  booktitle={Third workshop on computer vision for AR/VR at IEEE computer vision and pattern recognition (CVPR)},
  volume={2019},
  year={2019}
}
@article{dlib_info,
  title={Dlib-ml: A machine learning toolkit},
  author={King, Davis E},
  journal={The Journal of Machine Learning Research},
  volume={10},
  pages={1755--1758},
  year={2009},
  publisher={JMLR. org}
}
@article{An-introduction-to-tkinter,
  title={An introduction to tkinter},
  author={Lundh, Fredrik},
  journal={URL: www. pythonware. com/library/tkinter/introduction/index. htm},
  year={1999}
}
@inproceedings{comparing_python_guis,
  title={A brief demonstration of some Python GUI libraries},
  author={Podrzaj, Primoz},
  booktitle={Proceedings of the 8th International Conference on Informatics and Applications ICIA2019},
  pages={1--6},
  year={2019}
}
@book{nltk_info,
  title={Python 3 text processing with NLTK 3 cookbook},
  author={Perkins, Jacob},
  year={2014},
  publisher={Packt Publishing Ltd}
}
@incollection{Deep-learning:-RNNs-and-LSTM,
  title={Deep learning: {RNNs} and {LSTM}},
  author={DiPietro, Robert and Hager, Gregory D},
  booktitle={Handbook of medical image computing and computer assisted intervention},
  pages={503--519},
  year={2020},
  publisher={Elsevier}
}
@article{OG_LSTM,
  title={Long short-term memory},
  author={Memory, Long Short-Term},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={2010}
}
@article{lstm_diagram,
  title={LSTM: A search space odyssey},
  author={Greff, Klaus and Srivastava, Rupesh K and Koutn{\'\i}k, Jan and Steunebrink, Bas R and Schmidhuber, J{\"u}rgen},
  journal={IEEE transactions on neural networks and learning systems},
  volume={28},
  number={10},
  pages={2222--2232},
  year={2016},
  publisher={IEEE}
}
@INPROCEEDINGS{facial_expression_rec_lstm,
  author={Abdullah, Muhammad and Ahmad, Mobeen and Han, Dongil},
  booktitle={2020 International Conference on Electronics, Information, and Communication (ICEIC)}, 
  title={Facial Expression Recognition in Videos: An CNN-LSTM based Model for Video Classification}, 
  year={2020},
  volume={},
  number={},
  pages={1-3},
  doi={10.1109/ICEIC49074.2020.9051332}}
@Article{bilstm_diagram,
AUTHOR = {Zhang, Jinyue and Zi, Lijun and Hou, Yuexian and Deng, Da and Jiang, Wenting and Wang, Mingen},
TITLE = {A C-{BiLSTM} Approach to Classify Construction Accident Reports},
JOURNAL = {Applied Sciences},
VOLUME = {10},
YEAR = {2020},
NUMBER = {17},
ARTICLE-NUMBER = {5754},
URL = {https://www.mdpi.com/2076-3417/10/17/5754},
ISSN = {2076-3417},
ABSTRACT = {The construction sector is widely recognized as having the most hazardous working environment among the various business sectors, and many research studies have focused on injury prevention strategies for use on construction sites. The risk-based theory emphasizes the analysis of accident causes extracted from accident reports to understand, predict, and prevent the occurrence of construction accidents. The first step in the analysis is to classify the incidents from a massive number of reports into different cause categories, a task which is usually performed on a manual basis by domain experts. The research described in this paper proposes a convolutional bidirectional long short-term memory (C-BiLSTM)-based method to automatically classify construction accident reports. The proposed approach was applied on a dataset of construction accident narratives obtained from the Occupational Safety and Health Administration website, and the results indicate that this model performs better than some of the classic machine learning models commonly used in classification tasks, including support vector machine (SVM), na&iuml;ve Bayes (NB), and logistic regression (LR). The results of this study can help safety managers to develop risk management strategies.},
DOI = {10.3390/app10175754}
}
@inproceedings{sgd_diagram,
  title={An empirical analysis of generative adversarial network training times with varying batch sizes},
  author={Ghosh, Bhaskar and Dutta, Indira Kalyan and Carlson, Albert and Totaro, Michael and Bayoumi, Magdy},
  booktitle={2020 11th IEEE Annual Ubiquitous Computing, Electronics \& Mobile Communication Conference (UEMCON)},
  pages={0643--0648},
  year={2020},
  organization={IEEE}
}
@article{softmax,
  title={Exploring alternatives to softmax function},
  author={Banerjee, Kunal and Gupta, Rishi Raj and Vyas, Karthik and Mishra, Biswajit and others},
  journal={arXiv preprint arXiv:2011.11538},
  year={2020}
}
@article{softmax_diagram,
author = {Leixian, Shen and Zhang, Qingyun and Cao, Guoxu and Xu, He},
year = {2019},
month = {01},
pages = {590-598},
title = {Fall Detection System Based on Deep Learning and Image Processing in Cloud Environment},
isbn = {978-3-319-93658-1},
doi = {10.1007/978-3-319-93659-8_53}
}
@article{relu_diagram,
  title={Reduced dataset neural network model for manuscript character recognition},
  author={Islam, Mohammad Anwarul},
  year={2020}
}
@article{relu_description,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group UK London}
}
@article{relu_is_the_best,
  title={Searching for activation functions},
  author={Ramachandran, Prajit and Zoph, Barret and Le, Quoc V},
  journal={arXiv preprint arXiv:1710.05941},
  year={2017}
}
@article{disfluency,
  title={Fluency and disfluency},
  author={Lickley, Robin J},
  journal={The handbook of speech production},
  pages={445--474},
  year={2015},
  publisher={Wiley Online Library}
}
@article{vgg_architecture,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}
@article{cnn_intro,
  title={An introduction to convolutional neural networks},
  author={O'Shea, Keiron and Nash, Ryan},
  journal={arXiv preprint arXiv:1511.08458},
  year={2015}
}
@inproceedings{Convolutional-neural-network-(CNN)-for-image-detection-and-recognition,
  title={Convolutional neural network {(CNN)} for image detection and recognition},
  author={Chauhan, Rahul and Ghanshala, Kamal Kumar and Joshi, RC},
  booktitle={2018 first international conference on secure cyber computing and communication (ICSCCC)},
  pages={278--282},
  year={2018},
  organization={IEEE}
}
@inproceedings{Visualizing-and-understanding-convolutional-networks,
  title={Visualizing and understanding convolutional networks},
  author={Zeiler, Matthew D and Fergus, Rob},
  booktitle={Computer Vision--ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part I 13},
  pages={818--833},
  year={2014},
  organization={Springer}
}
#Might be useful for dropout
@inproceedings{max_pooling_&_dropout,
  title={Max-pooling dropout for regularization of convolutional neural networks},
  author={Wu, Haibing and Gu, Xiaodong},
  booktitle={Neural Information Processing: 22nd International Conference, ICONIP 2015, Istanbul, Turkey, November 9-12, 2015, Proceedings, Part I 22},
  pages={46--54},
  year={2015},
  organization={Springer}
}
@article{Pooling-methods-in-deep-neural-networks,
  title={Pooling methods in deep neural networks, a review},
  author={Gholamalinezhad, Hossein and Khosravi, Hossein},
  journal={arXiv preprint arXiv:2009.07485},
  year={2020}
}
@article{Attention-based-models-for-speech-recognition,
  title={Attention-based models for speech recognition},
  author={Chorowski, Jan K and Bahdanau, Dzmitry and Serdyuk, Dmitriy and Cho, Kyunghyun and Bengio, Yoshua},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}
@misc{lipreading_with_attention,
      title={LipFormer: Learning to Lipread Unseen Speakers based on Visual-Landmark Transformers}, 
      author={Feng Xue and Yu Li and Deyin Liu and Yincen Xie and Lin Wu and Richang Hong},
      year={2023},
      eprint={2302.02141},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@article{Effective-Approaches-to-Attention-based-Neural-Machine-Translation,
  author       = {Minh{-}Thang Luong and
                  Hieu Pham and
                  Christopher D. Manning},
  title        = {Effective Approaches to Attention-based Neural Machine Translation},
  journal      = {CoRR},
  volume       = {abs/1508.04025},
  year         = {2015},
  url          = {http://arxiv.org/abs/1508.04025},
  eprinttype    = {arXiv},
  eprint       = {1508.04025},
  timestamp    = {Mon, 13 Aug 2018 16:46:14 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/LuongPM15.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{A-review-on-the-attention-mechanism,
title = {A review on the attention mechanism of deep learning},
journal = {Neurocomputing},
volume = {452},
pages = {48-62},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2021.03.091},
url = {https://www.sciencedirect.com/science/article/pii/S092523122100477X},
author = {Zhaoyang Niu and Guoqiang Zhong and Hui Yu},
keywords = {Attention mechanism, Deep learning, Recurrent Neural Network (RNN), Convolutional Neural Network (CNN), Encoder-decoder, Unified attention model, Computer vision applications, Natural language processing applications},
abstract = {Attention has arguably become one of the most important concepts in the deep learning field. It is inspired by the biological systems of humans that tend to focus on the distinctive parts when processing large amounts of information. With the development of deep neural networks, attention mechanism has been widely used in diverse application domains. This paper aims to give an overview of the state-of-the-art attention models proposed in recent years. Toward a better general understanding of attention mechanisms, we define a unified model that is suitable for most attention structures. Each step of the attention mechanism implemented in the model is described in detail. Furthermore, we classify existing attention models according to four criteria: the softness of attention, forms of input feature, input representation, and output representation. Besides, we summarize network architectures used in conjunction with the attention mechanism and describe some typical applications of attention mechanism. Finally, we discuss the interpretability that attention brings to deep learning and present its potential future trends.}
}
@inproceedings{self_attention,
  title={Synthesizer: Rethinking self-attention for transformer models},
  author={Tay, Yi and Bahri, Dara and Metzler, Donald and Juan, Da-Cheng and Zhao, Zhe and Zheng, Che},
  booktitle={International conference on machine learning},
  pages={10183--10192},
  year={2021},
  organization={PMLR}
}
@article{Stochastic-gradient-descent,
  title={Stochastic gradient descent},
  author={Ketkar, Nikhil and Ketkar, Nikhil},
  journal={Deep learning with Python: A hands-on introduction},
  pages={113--132},
  year={2017},
  publisher={Springer}
}
@article{Stochastic-gradient-descent:-Recent-trends,
  title={Stochastic gradient descent: Recent trends},
  author={Newton, David and Yousefian, Farzad and Pasupathy, Raghu},
  journal={Recent advances in optimization and modeling of contemporary problems},
  pages={193--220},
  year={2018},
  publisher={INFORMS}
}
@article{adadelta_adaptive_learning_rate,
  title={Adadelta: an adaptive learning rate method},
  author={Zeiler, Matthew D},
  journal={arXiv preprint arXiv:1212.5701},
  year={2012}
}
@article{Learning-an-adaptive-learning-rate-schedule,
  title={Learning an adaptive learning rate schedule},
  author={Xu, Zhen and Dai, Andrew M and Kemp, Jonas and Metz, Luke},
  journal={arXiv preprint arXiv:1909.09712},
  year={2019}
}
@INPROCEEDINGS{learning_rate_causes_overfitting,
  author={Li, Haidong and Li, Jiongcheng and Guan, Xiaoming and Liang, Binghao and Lai, Yuting and Luo, Xinglong},
  booktitle={2019 15th International Conference on Computational Intelligence and Security (CIS)}, 
  title={Research on Overfitting of Deep Learning}, 
  year={2019},
  volume={},
  number={},
  pages={78-81},
  keywords={Training;Biological neural networks;Machine learning;Neurons;Stochastic processes;Mathematical model;Multilayer perceptrons;Deep learning;Neural network;Overfitting;Modified sigmoid},
  doi={10.1109/CIS.2019.00025}}
@inproceedings{what_is_overfitting,
  title={An overview of overfitting and its solutions},
  author={Ying, Xue},
  booktitle={Journal of physics: Conference series},
  volume={1168},
  pages={022022},
  year={2019},
  organization={IOP Publishing}
}
@inproceedings{adaptive_learning_rate_diagram,
  title={An SGD-based meta-learner with “growing” descent},
  author={Kulikovskikh, I and Prokhorov, S and Legovi{\'c}, T and {\v{S}}muc, T},
  booktitle={Journal of Physics: Conference Series},
  volume={1368},
  pages={052008},
  year={2019},
  organization={IOP Publishing},
}
@article{Adam_OG,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}
@article{benefit_of_decay,
  author       = {Kaichao You and
                  Mingsheng Long and
                  Michael I. Jordan and
                  Jianmin Wang},
  title        = {Learning Stages: Phenomenon, Root Cause, Mechanism Hypothesis, and
                  Implications},
  journal      = {CoRR},
  volume       = {abs/1908.01878},
  year         = {2019},
  url          = {http://arxiv.org/abs/1908.01878},
  eprinttype    = {arXiv},
  eprint       = {1908.01878},
  timestamp    = {Fri, 25 Oct 2019 18:47:18 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1908-01878.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{batch-size-on-the-generalizability,
title = {The effect of batch size on the generalizability of the convolutional neural networks on a histopathology dataset},
journal = {ICT Express},
volume = {6},
number = {4},
pages = {312-315},
year = {2020},
issn = {2405-9595},
doi = {https://doi.org/10.1016/j.icte.2020.04.010},
url = {https://www.sciencedirect.com/science/article/pii/S2405959519303455},
author = {Ibrahem Kandel and Mauro Castelli},
keywords = {Convolutional neural networks, Deep learning, Image classification, Medical images, Batch size},
abstract = {Many hyperparameters have to be tuned to have a robust convolutional neural network that will be able to accurately classify images. One of the most important hyperparameters is the batch size, which is the number of images used to train a single forward and backward pass. In this study, the effect of batch size on the performance of convolutional neural networks and the impact of learning rates will be studied for image classification, specifically for medical images. To train the network faster, a VGG16 network with ImageNet weights was used in this experiment. Our results concluded that a higher batch size does not usually achieve high accuracy, and the learning rate and the optimizer used will have a significant impact as well. Lowering the learning rate and decreasing the batch size will allow the network to train better, especially in the case of fine-tuning.}
}
@article{ batch-size-on-the-performance,
  title={Impact of training set batch size on the performance of convolutional neural networks for diverse datasets},
  author={Radiuk, Pavlo M},
  year={2017},
  publisher={Information Technology and Management Science}
}
@article{Adaptive-Batch-Sizes,
  author       = {Aditya Devarakonda and
                  Maxim Naumov and
                  Michael Garland},
  title        = {AdaBatch: Adaptive Batch Sizes for Training Deep Neural Networks},
  journal      = {CoRR},
  volume       = {abs/1712.02029},
  year         = {2017},
  url          = {http://arxiv.org/abs/1712.02029},
  eprinttype    = {arXiv},
  eprint       = {1712.02029},
  timestamp    = {Mon, 13 Aug 2018 16:46:36 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1712-02029.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@INPROCEEDINGS{exploration-of-CTC-acoustic-models,
  author={Miao, Yajie and Gowayyed, Mohammad and Na, Xingyu and Ko, Tom and Metze, Florian and Waibel, Alexander},
  booktitle={2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={An empirical exploration of {CTC} acoustic models}, 
  year={2016},
  volume={},
  number={},
  pages={2623-2627},
  keywords={Hidden Markov models;Training;Acoustics;Speech;Switches;Bidirectional control;Decoding;CTC;LSTMs;RNNs;acoustic modeling;speech recognition},
  doi={10.1109/ICASSP.2016.7472152}}
@INPROCEEDINGS{LCANet,
  author={Xu, Kai and Li, Dawei and Cassimatis, Nick and Wang, Xiaolong},
  booktitle={2018 13th IEEE International Conference on Automatic Face \& Gesture Recognition (FG 2018)}, 
  title={LCANet: End-to-End Lipreading with Cascaded {Attention}-{CTC}}, 
  year={2018},
  volume={},
  number={},
  pages={548-555},
  keywords={Feature extraction;Decoding;Road transportation;Speech recognition;Hidden Markov models;Neural networks;Visualization;Lipreading;ASR;attention mechanism;CTC;cascaded attention-CTC;deep neural network;3D CNN;highway network;Bi-GRU},
  doi={10.1109/FG.2018.00088}}
@article{LipReading-with-3D-2D-CNN-and-word-CTC-models,
  author       = {Dilip Kumar Margam and
                  Rohith Aralikatti and
                  Tanay Sharma and
                  Abhinav Thanda and
                  Pujitha A. K and
                  Sharad Roy and
                  Shankar M. Venkatesan},
  title        = {LipReading with 3D-2D-CNN {BLSTM-HMM} and word-CTC models},
  journal      = {CoRR},
  volume       = {abs/1906.12170},
  year         = {2019},
  url          = {http://arxiv.org/abs/1906.12170},
  eprinttype    = {arXiv},
  eprint       = {1906.12170},
  timestamp    = {Mon, 01 Jul 2019 13:00:07 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1906-12170.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@INPROCEEDINGS{ctc_faster_models,
  author={Lee, Jaesong and Watanabe, Shinji},
  booktitle={ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Intermediate Loss Regularization for CTC-Based Speech Recognition}, 
  year={2021},
  volume={},
  number={},
  pages={6224-6228},
  keywords={Training;Error analysis;Conferences;Stochastic processes;Signal processing;Acoustics;Decoding;end-to-end speech recognition;connectionist temporal classification;multitask learning;non-autoregressive},
  doi={10.1109/ICASSP39728.2021.9414594}}
@inproceedings{original_CTC,
  title={Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks},
  author={Graves, Alex and Fern{\'a}ndez, Santiago and Gomez, Faustino and Schmidhuber, J{\"u}rgen},
  booktitle={Proceedings of the 23rd international conference on Machine learning},
  pages={369--376},
  year={2006}
}
@inproceedings{Feature-extraction-methods:-a-review,
  title={Feature extraction methods: a review},
  author={Mutlag, Wamidh K and Ali, Shaker K and Aydam, Zahoor M and Taher, Bahaa H},
  booktitle={Journal of Physics: Conference Series},
  volume={1591},
  number={1},
  pages={012028},
  year={2020},
  organization={IOP Publishing}
}
@article{InceptionV3,
  author       = {Christian Szegedy and
                  Vincent Vanhoucke and
                  Sergey Ioffe and
                  Jonathon Shlens and
                  Zbigniew Wojna},
  title        = {Rethinking the Inception Architecture for Computer Vision},
  journal      = {CoRR},
  volume       = {abs/1512.00567},
  year         = {2015},
  url          = {http://arxiv.org/abs/1512.00567},
  eprinttype    = {arXiv},
  eprint       = {1512.00567},
  timestamp    = {Mon, 13 Aug 2018 16:49:07 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/SzegedyVISW15.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{Synchronous-Bidirectional-Learning-for-Multilingual-Lip-Reading,
  author       = {Mingshuang Luo and
                  Shuang Yang and
                  Xilin Chen and
                  Zitao Liu and
                  Shiguang Shan},
  title        = {Synchronous Bidirectional Learning for Multilingual Lip Reading},
  journal      = {CoRR},
  volume       = {abs/2005.03846},
  year         = {2020},
  url          = {https://arxiv.org/abs/2005.03846},
  eprinttype    = {arXiv},
  eprint       = {2005.03846},
  timestamp    = {Thu, 02 Dec 2021 17:27:17 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2005-03846.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{original_transformer,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@article{Google-colaboratory,
  title={Google colaboratory},
  author={Bisong, Ekaba and Bisong, Ekaba},
  journal={Building machine learning and deep learning models on google cloud platform: a comprehensive guide for beginners},
  pages={59--64},
  year={2019},
  publisher={Springer}
}
@inproceedings{LRS2,
  title={Lip reading sentences in the wild},
  author={Son Chung, Joon and Senior, Andrew and Vinyals, Oriol and Zisserman, Andrew},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={6447--6456},
  year={2017}
}
@article{LRS3,
  title={LRS3-TED: a large-scale dataset for visual speech recognition},
  author={Afouras, Triantafyllos and Chung, Joon Son and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1809.00496},
  year={2018}
}
@inproceedings{LRW-1000,
  title={{LRW}-1000: A naturally-distributed large-scale benchmark for lip reading in the wild},
  author={Yang, Shuang and Zhang, Yuanhang and Feng, Dalu and Yang, Mingmin and Wang, Chenhao and Xiao, Jingyun and Long, Keyu and Shan, Shiguang and Chen, Xilin},
  booktitle={2019 14th IEEE international conference on automatic face \& gesture recognition (FG 2019)},
  pages={1--8},
  year={2019},
  organization={IEEE}
}
@article{GLips,
  title={A multimodal german dataset for automatic lip reading systems and transfer learning},
  author={Schwiebert, Gerald and Weber, Cornelius and Qu, Leyuan and Siqueira, Henrique and Wermter, Stefan},
  journal={arXiv preprint arXiv:2202.13403},
  year={2022}
}
@inproceedings{Lip-reading-techniques,
  title={Lip reading techniques: A survey},
  author={Agrawal, Shreya and Omprakash, Verma Rahul and others},
  booktitle={2016 2nd International Conference on Applied and Theoretical Computing and Communication Technology (iCATccT)},
  pages={753--757},
  year={2016},
  organization={IEEE}
}
@inproceedings{Data-Splitting,
  title={Data splitting},
  author={Reitermanova, Zuzana and others},
  booktitle={WDS},
  volume={10},
  pages={31--36},
  year={2010},
  organization={Matfyzpress Prague}
}
@article{Data-Splitting_2,
  title={Data splitting},
  author={Picard, Richard R and Berk, Kenneth N},
  journal={The American Statistician},
  volume={44},
  number={2},
  pages={140--147},
  year={1990},
  publisher={Taylor \& Francis}
}
@article{jiwer_example,
  title={Transcribing Educational Videos Using Whisper: A preliminary study on using AI for transcribing educational videos},
  author={Rao, Ashwin},
  journal={arXiv preprint arXiv:2307.03200},
  year={2023}
}
@article{og_data_augmentation,
  title={A survey on image data augmentation for deep learning},
  author={Shorten, Connor and Khoshgoftaar, Taghi M},
  journal={Journal of big data},
  volume={6},
  number={1},
  pages={1--48},
  year={2019},
  publisher={SpringerOpen}
}
@article{dropout_for_overfitting,
  title={Avoiding overfitting: A survey on regularization methods for convolutional neural networks},
  author={Santos, Claudio Filipi Gon{\c{c}}alves Dos and Papa, Jo{\~a}o Paulo},
  journal={ACM Computing Surveys (CSUR)},
  volume={54},
  number={10s},
  pages={1--25},
  year={2022},
  publisher={ACM New York, NY}
}
@article{Transformers_in_vision:_A_survey,
  title={Transformers in vision: A survey},
  author={Khan, Salman and Naseer, Muzammal and Hayat, Munawar and Zamir, Syed Waqas and Khan, Fahad Shahbaz and Shah, Mubarak},
  journal={ACM computing surveys (CSUR)},
  volume={54},
  number={10s},
  pages={1--41},
  year={2022},
  publisher={ACM New York, NY}
}
@article{OG_vit,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}
@article{A_survey_of_visual_Transformers,
  title={A survey of visual Transformers},
  author={Liu, Yang and Zhang, Yao and Wang, Yixin and Hou, Feng and Yuan, Jin and Tian, Jiang and Zhang, Yang and Shi, Zhongchao and Fan, Jianping and He, Zhiqiang},
  journal={IEEE Transactions on Neural Networks and Learning Systems},
  year={2023},
  publisher={IEEE}
}
@article{regularization_for_DL,
  author       = {Jan Kukacka and
                  Vladimir Golkov and
                  Daniel Cremers},
  title        = {Regularization for Deep Learning: {A} Taxonomy},
  journal      = {CoRR},
  volume       = {abs/1710.10686},
  year         = {2017},
  url          = {http://arxiv.org/abs/1710.10686},
  eprinttype    = {arXiv},
  eprint       = {1710.10686},
  timestamp    = {Sat, 23 Jan 2021 01:20:25 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1710-10686.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{Convolutional-neural-network:-a-review-of...,
  title={Convolutional neural network: a review of models, methodologies and applications to object detection},
  author={Dhillon, Anamika and Verma, Gyanendra K},
  journal={Progress in Artificial Intelligence},
  volume={9},
  number={2},
  pages={85--112},
  year={2020},
  publisher={Springer}
}
@book{The_Hitch_Hiker's_Guide,
  title={The Hitchhiker's Guide to the Galaxy},
  author={Adams, Douglas},
  year={1980},
  publisher={New York: Harmony Books}
}
@article{cochlear_implants_low_income,
  title={Cost effectiveness of childhood cochlear implantation and deaf education in Nicaragua: a disability adjusted life year model},
  author={Saunders, James E and Barrs, David M and Gong, Wenfeng and Wilson, Blake S and Mojica, Karen and Tucci, Debara L},
  journal={Otology \& Neurotology},
  volume={36},
  number={8},
  pages={1349--1356},
  year={2015},
  publisher={LWW}
}
@article{Disability_in_low-income...,
  title={Disability in low-income countries: Issues and implications},
  author={Parnes, Penny and Cameron, Debra and Christie, Nancy and Cockburn, Lynn and Hashemi, Goli and Yoshida, Karen},
  journal={Disability and rehabilitation},
  volume={31},
  number={14},
  pages={1170--1180},
  year={2009},
  publisher={Taylor \& Francis}
}